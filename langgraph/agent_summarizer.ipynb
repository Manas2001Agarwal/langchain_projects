{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20dfa818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Annotated, List, TypedDict\n",
    "from langgraph.graph import StateGraph, START,END\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, RemoveMessage, AIMessage\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb544c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages:Annotated[List[AnyMessage],add_messages]\n",
    "    summary:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633aab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model=\"llama-3.1-8b-instant\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c9f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assistant(state:State):\n",
    "    summary = state.get(\"summary\")\n",
    "    \n",
    "    if summary:\n",
    "        summary_prompt = HumanMessage(f\"This is the summary of previous conversations: {summary}\")\n",
    "        return {\"messages\" : model.invoke([summary_prompt]+state['messages'])}\n",
    "    else:\n",
    "        return {\"messages\":model.invoke(state['messages'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_func(state:State):\n",
    "    summary = state.get(\"summary\")\n",
    "    \n",
    "    if summary:\n",
    "        summary_prompt = HumanMessage(f\"This is the summary from previous chat: {summary}\\nExtend this for following messages: \")\n",
    "        summary = model.invoke([summary_prompt]+state['messages']).content\n",
    "    else:\n",
    "        summary_prompt = HumanMessage(\"Summarize the above messages in less than 300 words: \")\n",
    "        summary = model.invoke(state['messages']+[summary_prompt]).content\n",
    "    \n",
    "    delete_messages = [RemoveMessage(id = m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"messages\":delete_messages,\"summary\":summary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fdcc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_condition(state:State):\n",
    "    if len(state['messages'])>6:\n",
    "        return \"summary_func\"\n",
    "    \n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e9a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceefba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "builder.add_node(\"assistant\",assistant)\n",
    "builder.add_node(\"summary_func\",summary_func)\n",
    "\n",
    "builder.add_edge(START,\"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\",summarize_condition,{\"summary_func\":\"summary_func\",END:END})\n",
    "builder.add_edge(\"summary_func\",END)\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b74a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"messages\":\"how are you\"},config = {\"configurable\":{\"thread_id\":\"firstchat\"}})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c514c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"messages\":\"explain me about gravity\"},config = {\"configurable\":{\"thread_id\":\"firstchat\"}})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343e8aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"messages\":\"how does it effect planets\"},config = {\"configurable\":{\"thread_id\":\"firstchat\"}})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf64ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"messages\":\"who discovered it\"},config = {\"configurable\":{\"thread_id\":\"firstchat\"}})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85304b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"thread_id\":\"firstchat\"}}\n",
    "graph.get_state(config).values.get(\"summary\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45530bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"a\":9}\n",
    "print(type(d.get('b')))\n",
    "if d.get(\"b\"):\n",
    "    print(\"found b\")\n",
    "else:\n",
    "    print(\"not found b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b0292",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"a\":9}\n",
    "b = d.get(\"b\")\n",
    "if b:\n",
    "    print(\"found b\")\n",
    "else:\n",
    "    print(\"not found b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3f1f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
