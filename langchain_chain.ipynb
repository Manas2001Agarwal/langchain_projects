{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a74b5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dda68e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model = \"deepseek-r1-distill-llama-70b\")\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"Generate 5 facts about {topic}. Only give facts in output\",\n",
    "    input_variables = [\"topic\"]\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt_template | model | parser\n",
    "\n",
    "result = chain.invoke({'topic':'black hole'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b977b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, so I need to come up with five facts about black holes. Hmm, where do I start? I remember that black holes are really dense objects in space, but I'm not entirely sure about the specifics. Let me think about what I've heard or read before.\n",
      "\n",
      "First, I think black holes have something called an event horizon. I believe that's the point where nothing, not even light, can escape once it gets too close. So maybe the first fact could be about the event horizon and the radius of no return. I should make sure to get the terminology right.\n",
      "\n",
      "Next, I remember something about supermassive black holes being at the centers of galaxies. Our own Milky Way has one, right? It's called Sagittarius A*, I think. That could be the second fact, mentioning that these large black holes are in galactic centers.\n",
      "\n",
      "Then, there's the information about the formation of black holes. They form from the gravitational collapse of massive stars. So when a star with a certain mass dies, it collapses in on itself and forms a black hole. That would make a good third fact.\n",
      "\n",
      "I also recall that black holes can pull in matter, which then forms an accretion disk around them. This disk heats up and emits X-rays, which is how we detect them indirectly. So that could be the fourth fact.\n",
      "\n",
      "Lastly, I think there's a limit to how small a black hole can be. I remember something called the Planck length, which is the smallest meaningful length in physics. So maybe the fifth fact could be that black holes can't be smaller than the Planck length.\n",
      "\n",
      "Wait, let me make sure I'm not mixing up any details. The event horizon is indeed the boundary beyond which nothing escapes. Supermassive black holes are huge and reside in galaxy centers. Stellar collapse leads to black hole formation. Accretion disks emit X-rays. And the minimum size is the Planck length. I think that's all correct. I should present these facts clearly and concisely.\n",
      "</think>\n",
      "\n",
      "1. Black holes have an event horizon, the boundary beyond which nothing, not even light, can escape, marking the radius of no return.  \n",
      "2. Supermassive black holes, such as Sagittarius A* in the Milky Way, are found at the centers of most galaxies.  \n",
      "3. Black holes form from the gravitational collapse of massive stars, typically those with more than three solar masses.  \n",
      "4. They are surrounded by accretion disks of heated matter that emit X-rays, aiding in their detection.  \n",
      "5. The smallest possible black hole is theorized to be the Planck length, the smallest meaningful length in physics.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62691980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +-------------+       \n",
      "     | PromptInput |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +----------+         \n",
      "      | ChatGroq |         \n",
      "      +----------+         \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51566985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text=\"Generate 5 pointer from below text\\n**Ultrasound in Pregnancy: A Comprehensive Report**\\n\\n**Introduction**\\n\\nUltrasound, also known as sonography, is a non-invasive medical imaging technique that uses high-frequency sound waves to produce images of the inside of the body. In pregnancy, ultrasound is widely used to monitor fetal development and detect any potential issues or complications. This report provides a detailed overview of ultrasound in pregnancy, including its history, techniques, benefits, and limitations.\\n\\n**History of Ultrasound in Pregnancy**\\n\\nThe first ultrasound image of a fetus was obtained in 1957 by a Scottish obstetrician, Ian Donald. Donald used a technique called A-mode ultrasound to visualize the fetus's movements and heartbeats. Since then, ultrasound technology has evolved significantly, and it is now a crucial tool in prenatal care.\\n\\n**Types of Ultrasound in Pregnancy**\\n\\nThere are several types of ultrasound techniques used in pregnancy, including:\\n\\n1. **Abdominal Ultrasound**: This is the most common type of ultrasound used in pregnancy. It involves placing a transducer on the abdomen to produce images of the fetus and placenta.\\n2. **Transvaginal Ultrasound (TVS)**: This type of ultrasound involves inserting a transducer into the vagina to produce high-resolution images of the fetus and cervix.\\n3. **Doppler Ultrasound**: This type of ultrasound uses sound waves to measure blood flow and detect any potential issues with fetal circulation.\\n4. **3D and 4D Ultrasound**: These advanced techniques use multiple transducers to produce detailed, three-dimensional images of the fetus.\\n\\n**Benefits of Ultrasound in Pregnancy**\\n\\nUltrasound has numerous benefits in pregnancy, including:\\n\\n1. **Monitoring Fetal Development**: Ultrasound allows healthcare providers to track fetal growth and development, detect any potential issues, and provide accurate due dates.\\n2. **Detection of Fetal Anomalies**: Ultrasound can detect fetal anomalies, such as heart defects, neural tube defects, and other structural abnormalities.\\n3. **Assessment of Placental Function**: Ultrasound can assess placental function, including the presence of a single placenta or a condition called placenta previa.\\n4. **Guidance for Medical Procedures**: Ultrasound is often used to guide medical procedures, such as amniocentesis and chorionic villus sampling (CVS).\\n\\n**Limitations of Ultrasound in Pregnancy**\\n\\nWhile ultrasound is a valuable tool in pregnancy, it is not without limitations. Some of the limitations include:\\n\\n1. **Availability and Accessibility**: Ultrasound machines and trained technicians may not be readily available in all areas.\\n2. **Operator Dependence**: The quality of the ultrasound images depends on the skill and experience of the operator.\\n3. **Technical Limitations**: Ultrasound images can be affected by factors such as fetal position, maternal obesity, and the presence of gas in the gastrointestinal tract.\\n4. **Radiation Exposure**: Ultrasound does not use ionizing radiation, making it a safer option than other imaging modalities.\\n\\n**Risks and Complications of Ultrasound in Pregnancy**\\n\\nWhile ultrasound is generally considered safe, there are some potential risks and complications to consider:\\n\\n1. **Fetal Heating**: Ultrasound can produce heat, which can potentially cause fetal heating.\\n2. **Fetal Trauma**: The high-frequency sound waves used in ultrasound can potentially cause fetal trauma.\\n3. **False Positives**: Ultrasound can produce false positive results for fetal anomalies or other conditions.\\n4. **Radiation Exposure**: While ultrasound does not use ionizing radiation, there is still some debate about the potential risks of long-term exposure to high-frequency sound waves.\\n\\n**Recommendations for Ultrasound in Pregnancy**\\n\\nTo ensure the safe and effective use of ultrasound in pregnancy, the following recommendations are made:\\n\\n1. **Use of Accredited Facilities**: Pregnant women should receive ultrasound services at accredited facilities with trained and experienced operators.\\n2. **Proper Use of Ultrasound Equipment**: Ultrasound machines and transducers should be properly maintained and calibrated to ensure accurate and reliable images.\\n3. **Minimization of Exposure**: Prenatal care providers should minimize fetal exposure to ultrasound, particularly in the third trimester.\\n4. **Informed Consent**: Pregnant women should be informed about the potential risks and benefits of ultrasound and provide informed consent before undergoing the procedure.\\n\\n**Conclusion**\\n\\nUltrasound is a valuable tool in prenatal care, providing accurate and reliable images of the fetus and placenta. While it has numerous benefits, it is not without limitations and potential risks. By understanding the history, techniques, benefits, and limitations of ultrasound in pregnancy, healthcare providers and pregnant women can make informed decisions about its use and ensure the safe and effective monitoring of fetal development.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatGroq(model = \"llama-3.1-8b-instant\")\n",
    "\n",
    "prompt_template1 = PromptTemplate(\n",
    "    template = \"Give me a detailed report on {topic}\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "prompt_template2 = PromptTemplate(\n",
    "    template = \"Generate 5 pointer from below text\\n{text}\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt_template1 | model | parser | prompt_template2 | parser\n",
    "\n",
    "result = chain.invoke({\"topic\":\"Ultrasound in pregnancy\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a37478f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +-------------+       \n",
      "     | PromptInput |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +----------+         \n",
      "      | ChatGroq |         \n",
      "      +----------+         \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4672eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableParallel\n",
    "prompt1 = PromptTemplate(\n",
    "    template = \"Generate short and simple notes from below text\\n{text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template=\"Generate 5 quiz questions from below text\\n{text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "prompt3 = PromptTemplate(\n",
    "    template = \"Merge given notes: {notes} and quiz questions {quiz} into one text\",\n",
    "    input_variables=['notes','quiz']\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91cf2943",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\n",
    "\n",
    "The advantages of support vector machines are:\n",
    "\n",
    "Effective in high dimensional spaces.\n",
    "\n",
    "Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "\n",
    "Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "\n",
    "Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "The disadvantages of support vector machines include:\n",
    "\n",
    "If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\n",
    "\n",
    "SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51afe01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel({\n",
    "    'notes' : prompt1 | model | parser,\n",
    "    'quiz' : prompt2 | model | parser\n",
    "})\n",
    "\n",
    "merge_chain = prompt3 | model | parser\n",
    "\n",
    "chain = parallel_chain | merge_chain\n",
    "\n",
    "result = chain.invoke({\"text\" : text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f673d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Support Vector Machines (SVMs) Notes**\n",
      "\n",
      "**Overview**\n",
      "Support Vector Machines (SVMs) are supervised learning methods that can be used for classification, regression, and outliers detection. They are effective in handling high-dimensional spaces and can be memory-efficient using a subset of training points, known as support vectors.\n",
      "\n",
      "**Advantages**\n",
      "- **Effective in high-dimensional spaces**: SVMs can handle cases where dimensions are greater than the number of samples.\n",
      "- **Memory-efficient**: SVMs use a subset of training points (support vectors), making them memory-efficient.\n",
      "- **Versatile**: Various Kernel functions are available, allowing SVMs to be applied to different types of problems.\n",
      "- **Outliers detection**: SVMs can be used for outliers detection, making them a useful tool for identifying unusual data points.\n",
      "\n",
      "**Disadvantages**\n",
      "- **Over-fitting**: SVMs can suffer from over-fitting if not chosen carefully, particularly when selecting the right Kernel functions and regularization term.\n",
      "- **No direct probability estimates**: SVMs do not provide direct probability estimates, which can be calculated using cross-validation, but this process can be expensive.\n",
      "\n",
      "**Quiz Questions**\n",
      "\n",
      "1. What type of learning methods are Support Vector Machines (SVMs), and what tasks can they be used for?\n",
      "A) Unsupervised learning, classification, regression\n",
      "B) Supervised learning, classification, regression, outliers detection\n",
      "C) Unsupervised learning, regression\n",
      "D) Supervised learning, classification\n",
      "\n",
      "Answer: B) Supervised learning, classification, regression, outliers detection\n",
      "\n",
      "2. What is the advantage of SVMs when dealing with high-dimensional spaces?\n",
      "A) It is less memory efficient\n",
      "B) It requires a lot of samples\n",
      "C) It is effective\n",
      "D) It is slow to train\n",
      "\n",
      "Answer: C) It is effective\n",
      "\n",
      "3. What is the term for the subset of training points used in the decision function of an SVM?\n",
      "A) Support vectors\n",
      "B) Kernel functions\n",
      "C) Regularization term\n",
      "D) Outliers\n",
      "\n",
      "Answer: A) Support vectors\n",
      "\n",
      "4. Why is it crucial when using SVMs to choose the right Kernel functions and regularization term?\n",
      "A) To avoid over-fitting\n",
      "B) To improve training speed\n",
      "C) To increase memory usage\n",
      "D) To decrease accuracy\n",
      "\n",
      "Answer: A) To avoid over-fitting\n",
      "\n",
      "5. How are probability estimates calculated for SVMs, and what is the cost associated with this calculation?\n",
      "A) Through a simple calculation, no cost\n",
      "B) Using a straightforward formula, no cost\n",
      "C) Using five-fold cross-validation, an expensive process\n",
      "D) Using a predefined table, no cost\n",
      "\n",
      "Answer: C) Using five-fold cross-validation, an expensive process\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "decc6229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          +---------------------------+            \n",
      "          | Parallel<notes,quiz>Input |            \n",
      "          +---------------------------+            \n",
      "                ***             ***                \n",
      "              **                   **              \n",
      "            **                       **            \n",
      "+----------------+              +----------------+ \n",
      "| PromptTemplate |              | PromptTemplate | \n",
      "+----------------+              +----------------+ \n",
      "          *                             *          \n",
      "          *                             *          \n",
      "          *                             *          \n",
      "    +----------+                  +----------+     \n",
      "    | ChatGroq |                  | ChatGroq |     \n",
      "    +----------+                  +----------+     \n",
      "          *                             *          \n",
      "          *                             *          \n",
      "          *                             *          \n",
      "+-----------------+            +-----------------+ \n",
      "| StrOutputParser |            | StrOutputParser | \n",
      "+-----------------+            +-----------------+ \n",
      "                ***             ***                \n",
      "                   **         **                   \n",
      "                     **     **                     \n",
      "          +----------------------------+           \n",
      "          | Parallel<notes,quiz>Output |           \n",
      "          +----------------------------+           \n",
      "                         *                         \n",
      "                         *                         \n",
      "                         *                         \n",
      "                +----------------+                 \n",
      "                | PromptTemplate |                 \n",
      "                +----------------+                 \n",
      "                         *                         \n",
      "                         *                         \n",
      "                         *                         \n",
      "                   +----------+                    \n",
      "                   | ChatGroq |                    \n",
      "                   +----------+                    \n",
      "                         *                         \n",
      "                         *                         \n",
      "                         *                         \n",
      "                +-----------------+                \n",
      "                | StrOutputParser |                \n",
      "                +-----------------+                \n",
      "                         *                         \n",
      "                         *                         \n",
      "                         *                         \n",
      "            +-----------------------+              \n",
      "            | StrOutputParserOutput |              \n",
      "            +-----------------------+              \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bebb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema.runnable import RunnableBranch, RunnableLambda\n",
    "\n",
    "groq_model = ChatGroq(model = \"llama-3.1-8b-instant\")\n",
    "\n",
    "class Sentiment(BaseModel):\n",
    "    sentiment : Literal['positive','negative'] = Field(description=\"Sentiment of product review : positive or negative\")\n",
    "    \n",
    "parser = PydanticOutputParser(pydantic_object=Sentiment)\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    template=\"Give a review: {review}\\nclassify its sentiment into positive or negative. {format_instructions}\",\n",
    "    input_variables=['review'],\n",
    "    partial_variables={\"format_instructions\":parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt1 | groq_model | parser\n",
    "result = chain.invoke({\"review\":\"This is very googd smartphone. Good RAM and Good processor\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fae8879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment='positive'\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68204a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = PromptTemplate(\n",
    "    template = \"Write an appropriate response to this positive feedback:\\n{review}\\nOnly give response in output\",\n",
    "    input_variables=['review']\n",
    ")\n",
    "\n",
    "prompt3 = PromptTemplate(\n",
    "    template = \"Write an appropriate response to this negative feedback:\\n{review}\\nOnly give response in output\",\n",
    "    input_variables=['review']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10b924f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_parser = StrOutputParser()\n",
    "branch_chain = RunnableBranch(\n",
    "    (lambda x: x.sentiment == \"positive\",prompt2 | groq_model | str_parser),\n",
    "    (lambda x: x.sentiment == \"negative\",prompt3 | groq_model | str_parser),\n",
    "    RunnableLambda(lambda x: \"could not find sentiment\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba956b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I apologize that our service/product didn\\'t meet your expectations. Can you please provide more details about your experience, so we can better understand what went wrong and how we can improve?\"'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain = chain | branch_chain \n",
    "final_chain.invoke({\"review\":\"This is very bad smartphone. Worst performance\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b86ace1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-------------+      \n",
      "    | PromptInput |      \n",
      "    +-------------+      \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "   +----------------+    \n",
      "   | PromptTemplate |    \n",
      "   +----------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "      +----------+       \n",
      "      | ChatGroq |       \n",
      "      +----------+       \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "+----------------------+ \n",
      "| PydanticOutputParser | \n",
      "+----------------------+ \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "       +--------+        \n",
      "       | Branch |        \n",
      "       +--------+        \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "    +--------------+     \n",
      "    | BranchOutput |     \n",
      "    +--------------+     \n"
     ]
    }
   ],
   "source": [
    "final_chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb58516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "906ecc44",
   "metadata": {},
   "source": [
    "Langchain Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74adb624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'first_Response'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "class NakliLLM:\n",
    "    def __init__(self):\n",
    "        print(\"LLM created\")\n",
    "        \n",
    "    def predict(self,prompt):\n",
    "        response_list = [\"first_Response\",\"second_response\",\"third_response\"]\n",
    "        return random.choice(response_list)\n",
    "    \n",
    "nakli_llm = NakliLLM()\n",
    "nakli_llm.predict(\"what is your name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    template = \"for the given topic generate a linkedin post - {topic}\",\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template = \"for the given topic generate a twitter post - {topic}\",\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "model = ChatGroq(model = \"llama-3.1-8b-instant\")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"linkedin\" : prompt1 | model | parser,\n",
    "    \"tweet\" : prompt2 | model | parser\n",
    "})\n",
    "\n",
    "prompt3 = PromptTemplate(\n",
    "    template = \"combine this linkedin post -\\n{linkedin}\\nwith this tweet on twiiter -\\n{tweet} and summarize it in less than 100 words\",\n",
    "    input_variables=['linkedin','tweet']\n",
    ")\n",
    "\n",
    "chain = parallel_chain | prompt3 | model | parser\n",
    "\n",
    "result = chain.invoke({\"topic\":\"black hole\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f30ae5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Mystery of the Universe: Unveiling the Secrets of Black Holes**\n",
      "\n",
      "Black holes are cosmic phenomena where gravity is so strong that nothing, not even light, can escape. Formed from massive star collapses, they have an event horizon, a point of no return. Scientists study black holes to understand the universe's behavior in extreme environments. With advancements in technology, direct observations are becoming possible, offering new insights into the universe.\n",
      "\n",
      "**Mind-blowing Fact:** Black holes are so dense that not even light can escape their gravitational pull, leaving scientists with more questions than answers.\n",
      "\n",
      "**Join the Conversation** Share your thoughts on black holes and the universe! #BlackHoles #SpaceExploration #Astrophysics #Science #Mystery #Universe\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e7a94e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linkedin': \"**Breaking Down Barriers in Medical Imaging: The Power of Ultrasound Technology**\\n\\nAs a medical professional or someone passionate about healthcare, you're likely no stranger to the importance of accurate and timely diagnoses. One essential tool in our toolkit is ultrasound technology, which has revolutionized the way we visualize and understand the human body.\\n\\nIn recent years, advancements in ultrasound technology have led to improved image quality, increased accessibility, and enhanced patient outcomes. From routine check-ups to complex procedures, ultrasound has become an indispensable asset in various medical specialties, including obstetrics, cardiology, and radiology.\\n\\nAt the heart of ultrasound lies the concept of high-frequency sound waves, which are used to create detailed images of internal organs and tissues. This non-invasive and pain-free modality has numerous benefits, including:\\n\\n **Increased patient comfort**: No radiation, no discomfort, and no risks associated with ionizing radiation.\\n **Improved diagnostic accuracy**: Enhanced image quality enables more accurate diagnoses and treatment plans.\\n **Enhanced patient care**: Rapid results and real-time feedback facilitate timely interventions and improved patient outcomes.\\n\\nAs we continue to push the boundaries of ultrasound technology, we're witnessing exciting innovations, such as:\\n\\n **Portable and handheld devices**: Revolutionizing point-of-care imaging and expanding access to healthcare services.\\n **Artificial intelligence and machine learning applications**: Enhancing image analysis, automation, and decision support.\\n **Advanced probe technologies**: Improving image quality, resolution, and depth penetration.\\n\\nAt [Your Organization/Company Name], we're committed to harnessing the full potential of ultrasound technology to transform healthcare outcomes. Our team of experts is dedicated to:\\n\\n **Staying at the forefront of innovation**: Continuously exploring new technologies and applications to drive progress in medical imaging.\\n **Providing education and training**: Equipping healthcare professionals with the skills and knowledge needed to master ultrasound techniques.\\n **Advancing patient care**: Collaborating with clinicians to develop and implement evidence-based ultrasound protocols.\\n\\nJoin the conversation and let's continue to push the boundaries of ultrasound technology together! What are your thoughts on the future of ultrasound in healthcare? Share your experiences, insights, and ideas in the comments below.\\n\\n#Ultrasound #MedicalImaging #Healthcare #Innovation #PatientCare #Advancements #Technology #HealthcareProfessionals #MedicalSpecialties #Obstetrics #Cardiology #Radiology\",\n",
       " 'tweet': '\"Did you know that the first #Ultrasound scan was performed in 1958 by Australian physiologist Dr. Ian Donald? This non-invasive imaging technique has revolutionized medical diagnosis & saved countless lives. #MedicalBreakthrough #Healthcare\"'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_chain.invoke({\"topic\":\"ultrasound\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d01d929e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': 'Why did the LangChain model go to therapy? \\n\\nBecause it was struggling to chain its thoughts together.',\n",
       " 'joke_explanation': 'This joke is a play on words related to the field of Artificial Intelligence and Natural Language Processing (NLP), specifically about a type of model called a LangChain model.\\n\\nA LangChain model is a type of AI model designed to process and generate human-like language sequences. The term \"LangChain\" is a reference to the concept of \"linking\" or \"chaining\" together words and ideas to form coherent sentences.\\n\\nIn the joke, the punchline \"struggling to chain its thoughts together\" has a double meaning:\\n\\n1. In a literal sense, the LangChain model\\'s primary function is to \"chain\" together words and ideas to form coherent language sequences. So, it\\'s a play on words that the model is struggling with its core function.\\n2. In a figurative sense, \"chain its thoughts together\" is a common idiomatic expression that means to organize or connect one\\'s thoughts in a logical and coherent manner. So, the joke is saying that the LangChain model is struggling to do something that humans take for granted – organizing their thoughts.\\n\\nThe joke is a clever play on words that pokes fun at the idea that even AI models can have their own quirks and struggles, just like humans do.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    template = \"for the given topic generate a joke - {topic}\",\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "seq_chain = prompt1 | model | parser\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template=\"Given a joke, explain it -\\n{joke}\",\n",
    "    input_variables=['joke']\n",
    ")\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    'joke' : RunnablePassthrough(),\n",
    "    'joke_explanation' : prompt2 | model | parser\n",
    "})\n",
    "\n",
    "final_chain = seq_chain | parallel_chain\n",
    "\n",
    "result = final_chain.invoke({\"topic\" : \"langchain\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca7792d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': 'Why did the actress bring a ladder to the set?\\n\\nBecause she wanted to take her career to the next level.', 'word_count': 21}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "def word_count(string):\n",
    "    return len(string.split())\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    template = \"for the given topic generate a joke - {topic}\",\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "seq_chain = prompt1 | model | parser\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"joke\" : RunnablePassthrough(),\n",
    "    \"word_count\" : RunnableLambda(word_count)\n",
    "})\n",
    "\n",
    "final_chain = seq_chain | parallel_chain\n",
    "result = final_chain.invoke({\"topic\":\"actrees\"})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb2466b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             +-------------+               \n",
      "             | PromptInput |               \n",
      "             +-------------+               \n",
      "                     *                     \n",
      "                     *                     \n",
      "                     *                     \n",
      "            +----------------+             \n",
      "            | PromptTemplate |             \n",
      "            +----------------+             \n",
      "                     *                     \n",
      "                     *                     \n",
      "                     *                     \n",
      "               +----------+                \n",
      "               | ChatGroq |                \n",
      "               +----------+                \n",
      "                     *                     \n",
      "                     *                     \n",
      "                     *                     \n",
      "           +-----------------+             \n",
      "           | StrOutputParser |             \n",
      "           +-----------------+             \n",
      "                     *                     \n",
      "                     *                     \n",
      "                     *                     \n",
      "    +--------------------------------+     \n",
      "    | Parallel<joke,word_count>Input |     \n",
      "    +--------------------------------+     \n",
      "              **           **              \n",
      "            **               **            \n",
      "          **                   **          \n",
      "+-------------+            +------------+  \n",
      "| Passthrough |            | word_count |  \n",
      "+-------------+            +------------+  \n",
      "              **           **              \n",
      "                **       **                \n",
      "                  **   **                  \n",
      "   +---------------------------------+     \n",
      "   | Parallel<joke,word_count>Output |     \n",
      "   +---------------------------------+     \n"
     ]
    }
   ],
   "source": [
    "final_chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a9b07cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a summary of the report in less than 100 words:\n",
      "\n",
      "The conflict between Russia and Ukraine began in 2014 after Ukraine's pro-Russian President Viktor Yanukovych was ousted, leading to Russia's annexation of Crimea and a separatist conflict in eastern Ukraine. The conflict is driven by Ukraine's pro-Western orientation, Russia's economic interests, ethnic and cultural tensions, and NATO expansion. The humanitarian crisis has resulted in over 3,000 deaths, 1 million displaced people, and widespread economic damage. Diplomatic efforts continue, with the international community divided on how to respond. Recommendations include increased diplomatic efforts, humanitarian aid, economic support, and security measures.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough, RunnableBranch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatGroq(model = \"llama-3.1-8b-instant\")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    template = \"Generate a report in greater than 500 words on the given topic -\\n{topic}\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template = \"Summarize the given report in less than 100 words -\\n{report}\",\n",
    "    input_variables=[\"report\"]\n",
    ")\n",
    "\n",
    "seq_chain = prompt1 | model | parser\n",
    "\n",
    "conditional_branch = RunnableBranch(\n",
    "    (lambda x: len(x.split()) > 500, prompt2 | model | parser),\n",
    "    RunnablePassthrough()\n",
    ")\n",
    "\n",
    "final_chain = seq_chain | conditional_branch\n",
    "\n",
    "result = final_chain.invoke({\"topic\":\"Russia vs Ukraine\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9015250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader('file.txt',encoding='utf-8')\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9098e253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93309a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7c5ab8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=' Google opens up its AI language model PaLM to challenge OpenAI and GPT-3 Google \n",
      "offers developers access to one of its most advanced AI language models: PaLM. The search \n",
      "giant is launching an API for PaLM alongside a number of AI enterprise tools it says will \n",
      "help businesses generate text, images, code, videos, audio, and more from simple natural \n",
      "language prompts. \n",
      "\n",
      "PaLM is a large language model, or LLM, similar to the GPT series created \n",
      "by OpenAI or Meta's LLaMA family of models. Google first announced PaLM in April 2022. Like \n",
      "other LLMs, PaLM is a flexible system that can potentially carry out all sorts of text \n",
      "generation and editing tasks. You could train PaLM to be a conversational chatbot like \n",
      "ChatGPT, for example, or you could use it for tasks like summarizing text or even writing code. \n",
      "(It's similar to features Google also announced today for its Workspace apps like Google Docs \n",
      "and Gmail.)\n",
      "' metadata={'source': 'file.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bffa775e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'file.txt'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cde58625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Google has opened access to its advanced AI language model, PaLM, to developers. This move aims to challenge existing AI models, such as OpenAI's GPT-3. PaLM, a large language model, can perform various tasks like text generation, editing, and even code writing, and can potentially be trained for conversational chatbots or other applications. Google is also launching an API and AI enterprise tools to help businesses utilize PaLM's capabilities.\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatGroq(model = \"llama-3.1-8b-instant\")\n",
    "prompt = PromptTemplate(\n",
    "    template=\"write a summary for the below text-\\n{text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"text\":docs[0].page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ae05be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"/Users/mukulagarwal/Desktop/Projects/langchain/Developers_Guide_to_RAG.pdf\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f55973b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf7ba6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "© Confluent Inc. 2025 7\n",
      "The Confluent Data Streaming Platform enables development teams to: \n",
      "Prevent hallucinations\n",
      "Use post-processing to validate that LLM outputs are correct by having a consumer \n",
      "group or Flink SQL check the generated response against policy and customer data \n",
      "in Confluent. \n",
      "Improve LLMs with real-time, domain-specific context\n",
      "Integrate disparate data into a single source of truth for real-time contextualization \n",
      "and securely share relevant data. Additionally, safeguard data such as proprietary \n",
      "information or PII through Stream Governance (e.g., schema rules). Capture real-\n",
      "time events, enrich them, and convert them to vector embeddings for immediate use \n",
      "by your AI tools, models, and applications.\n",
      "Lower the barrier to entry\n",
      "Instead of building custom integrations or investing in more infrastructure to \n",
      "support RAG, leverage a fully managed Data Streaming Platform (with fully managed \n",
      "connectors, Flink as a cloud-native service, Stream Governance) in order to focus \n",
      "on building GenAI applications rather than managing data infrastructure. \n",
      "Scale independently for greater agility\n",
      "Decouple teams, systems, and technologies to work more autonomously and \n",
      "efficiently. For example, different teams can work on different aspects of RAG \n",
      "applications. Keep what you have and use the LLM (e.g., GPT, Gemini, LlaMA), vector \n",
      "store (e.g., Pinecone, Weaviate, Milvus), and embedding model you prefer. Modular \n",
      "components can be substituted as technology improves, with no vendor lock-in. \n",
      "Easily discover, access, and reuse trusted data products.\n",
      "There are four key steps for building a RAG architecture, and in the following sections, \n",
      "we’ll cover how you can use Data Streaming Platform features for each step:\n",
      "1. Data Augmentation – Preparing data for a real-time knowledge base and \n",
      "contextualization in LLM queries by populating a vector database. \n",
      "2. Inference – Connecting relevant information with each prompt, contextualizing \n",
      "what users are asking for and ensuring GenAI applications are built to handle those \n",
      "responses.\n",
      "3. Workflows – Parsing natural language, synthesizing the necessary information, and \n",
      "using a reasoning agent to determine what to do next to optimize performance (e.g., \n",
      "querying a database, getting information from cache, calling an LLM with a different \n",
      "prompt).\n",
      "4. Post-Processing – Validating LLM outputs and enforcing business logic and \n",
      "compliance requirements to detect hallucinations and ensure the LLM has returned a \n",
      "trustworthy answer.\n"
     ]
    }
   ],
   "source": [
    "print(docs[6].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3174df4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Adobe PDF Library 17.0',\n",
       " 'creator': 'Adobe InDesign 20.0 (Macintosh)',\n",
       " 'creationdate': '2025-02-19T11:51:19+00:00',\n",
       " 'moddate': '2025-02-19T11:51:28+00:00',\n",
       " 'trapped': '/False',\n",
       " 'source': '/Users/mukulagarwal/Desktop/Projects/langchain/Developers_Guide_to_RAG.pdf',\n",
       " 'total_pages': 22,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "29e9c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader,PyPDFLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    path = \"/Users/mukulagarwal/Desktop/Projects/langchain\",\n",
    "    glob = \"*.pdf\",\n",
    "    loader_cls= PyPDFLoader\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "81e0e8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b052c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "docs = loader.lazy_load()\n",
    "\n",
    "length_of_docs = [len(doc.page_content) for doc in docs]\n",
    "length_of_docs = np.array(length_of_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "51bcd8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2252.  , 4331.  , 4576.4 , 4583.2 , 4588.64])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(length_of_docs,q=[50,95,99.0,99.5,99.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c98d2db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader,SeleniumURLLoader,WhatsAppChatLoader\n",
    "\n",
    "url = \"https://www.flipkart.com/poco-f6-5g-titanium-256-gb/p/itmb5451dec31503?pid=MOBHYUZGDMF7UJMG&lid=LSTMOBHYUZGDMF7UJMG8JGACN&marketplace=FLIPKART&q=poco+f7+5g&store=tyy%2F4io&srno=s_1_1&otracker=AS_Query_OrganicAutoSuggest_4_4_na_na_na&otracker1=AS_Query_OrganicAutoSuggest_4_4_na_na_na&fm=organic&iid=70ebcf16-5d87-409d-866d-d771e849d815.MOBHYUZGDMF7UJMG.SEARCH&ppt=hp&ppn=homepage&ssid=4012nzi7cw0000001750786422030&qH=80052f146eeb1ccd\"\n",
    "\n",
    "loader = WebBaseLoader(url)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ee0457fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   POCO F6 5G ( 256 GB Storage, 12 GB RAM ) Online at Best Price On Flipkart.com        Explore PlusLoginBecome a Seller More CartAdd to cart Buy NowHomeMobiles & AccessoriesMobilesPOCO MobilesPOCO F6 5G (Titanium, 256 GB) (12 GB RAM)\n",
      "CompareSharePOCO F6 5G (Titanium, 256 GB)¬†¬†(12 GB RAM)4.37,417 Ratings¬†&¬†732 ReviewsExtra ‚Çπ12000 off‚Çπ23,999‚Çπ35,99933% offiAvailable offersBank Offer100% Cashback upto 500Rs on Axis Bank SuperMoney Rupay CC UPI transactions on super.money UPIT&CBank Offer5% cashback on Flipkart Axis Bank Credit Card upto ‚Çπ4,000 per statement quarterT&CSpecial PriceGet extra ‚Çπ12000 off (price inclusive of cashback/coupon)T&CNo Cost EMI on Bajaj FinservT&CView 3 more offersBuy without Exchange‚Çπ23,999Buy with Exchangeup to ‚Çπ18,400 offEnter pincode to check if exchange is available1 Year Manufacturer Warranty for Phone and 6 Months Warranty for In the Box AccessoriesKnow MoreColorBlackTitaniumPlease select a Color to proceed‚úïStorage256 GB256 GB512 GB512 GBPlease select a Storage to proceed‚úïRAM8 GB8 GB12 GB12 GBPlease select a RAM to proceed‚úïDeliveryCheckEnter pincodeDelivery by28 Jun, Saturday?if ordered before 1:03 AMView DetailsHighlights12 GB RAM | 256 GB ROM16.94 cm (6.67 inch) Display50MP (OIS) + 8MP | 20MP Front Camera5000 mAh Battery8s Gen3 ProcessorEasy Payment OptionsCash on DeliveryNet banking & Credit/ Debit/ ATM cardView DetailsSellerFlashstar Commerce4.77 Days Service Center Replacement/Repair?GST invoice available?See other sellersDescriptionWith its 3.0 GHz CPU and 4 nm TSMC technology, the POCO F6, which is powered by the Snapdragon 8s Gen 3 processor, achieves over 1.5 million AnTuTu points. Its architecture, which includes the modem, RAM, display, and ISP, is shared with the 8 Gen 3. Its POCO Ice-Loop System efficiently cools the system, while AI rendering and performance scheduling improves the responsiveness and looks of the game. The gadget has a dazzling 1.5K AMOLED display with a refresh rate of 120 Hz and a brightness of 2400 nits, along with 12GB LPDDR5X RAM and up to 512GB UFS 4.0 storage. With OIS and EIS capabilities, the 50MP camera records 4K video at 60 frames per second. Photo editing is improved with features like AI Magic Eraser Pro and AI Image Expansion. A 5000 mAh battery is charged to 50% capacity in 11 minutes by the 90 W turbocharger. The DSDA mode and smart SIM changeover maximise network efficiency.Read MoreProduct DescriptionPowerful ProcessorThe Snapdragon 8s Gen 3 Processor, which powers the POCO F6, boasts an astounding 1.5 million plus AnTuTu points. This includes a powerful 3.0 GHz CPU and a 4 nm TSMC production technique.\n",
      "Brilliant PerformanceThe Snapdragon 8s Gen 3 and Qualcomm's most recent flagship 8 Gen 3 processor have the same architecture. It is identical to the 8 Gen 3 in terms of modem architecture, memory, display, and ISP.\n",
      "Efficient CoolingExperience high-caliber performance without the heat thanks to the POCO F6's flawless POCO Ice-Loop System. Because it uses a specific vapour-liquid separation method, this is up to three times more efficient than a traditional VC cooling configuration.\n",
      "AI SupremacyAI performance scheduling comprises real-time frame stabilisation, thread management, and frequency modulation. Also, AI rendering allows you to break past the game's original picture quality and provide more intricate and lifelike visual effects by using AI capabilities to recreate the rendering model and render the image point-to-point. Moreover, AI control recognises the user's intended to touch, incorporates system resources, boosts wake-up and operation reaction times, and enhances first-frame and continuous response times.\n",
      "Large StorageWith its automatic 12 GB LPDDR5X RAM and up to 512 GB UFS 4.0 Storage, which allows for quicker read and write speeds, the POCO F6 completes the Performance Trinity.\n",
      "Vibrant DisplayThe stunning 1.5K AMOLED display on the POCO F6 boasts a refresh rate of 120 Hz and can produce up to 68.7 billion colours. The phone boasts an adaptive HDR 10+ display and supports Dolby Suite, which includes Dolby Atmos and Dolby Vision. The cherry on top is a maximum brightness of 2400 nits and a Touch sampling rate of up to 480 Hz.\n",
      "Incredible Camera SetupThe 50MP main camera of this smartphone can shoot 4K video at 60 frames per second. Also available for recording is HDR10+ (4K at 30 frames per second). Because of the f/1.59 aperture, it also includes both OIS and EIS technologies for a shake-free experience and improved low-light shooting.\n",
      "AI Magic Eraser ProYou have AI Magic Eraser Pro, which allows you to eliminate objects or topics, and AI Image Expansion, a clever AI that can enlarge the original image.\n",
      "90 W TurbochargerThe F6 will feature a 90 W turbocharger, which is a first for a POCO. In 11 minutes, this will charge your device to 50%. You can now enjoy a full day of standby, 50 hours of music, 17 hours of streaming, and 30 hours of calling thanks to the huge 5000 mAh battery.\n",
      "Smart SIM SwitchAdditionally, the phone has a few network optimisations that are only made possible by the SoC. Simultaneous engagement of both SIMs is guaranteed by the DSDA mode. You may have smooth transitions between the SIMs with the Smart SIM switch and the lift mode, which significantly cuts down on network recovery time.\n",
      "View all featuresSpecificationsGeneralIn The BoxHandset, 90W Charger, USB Type-C Cable, Sim Eject Tool, Protective Case, Quick Start Guide, Warranty CardModel NumberMZB0H51INModel NameF6 5GColorTitaniumBrowse TypeSmartphonesSIM TypeDual SimHybrid Sim SlotNoTouchscreenYesOTG CompatibleYesQuick ChargingYesSAR ValueSAR Limit: 1.6 W/kg, Head SAR: 0.848 W/kg, Body SAR: 0.628 W/kgDisplay FeaturesDisplay Size16.94 cm (6.67 inch)Resolution2712 x 1220 PixelsGPUAdreno 735Display Type1.5K AMOLED DisplayOther Display Features120Hz, Dolby Vision, Contrast: 5,000,000:1, 68 Billion+ Colors, Corning Gorilla Glass Victus, 1920Hz PWM Dimming, 2400 Nits Peak Brightness, 2160Hz Instantaneous Touch Sampling Rate, In-Display Fingerprint, Screen-to-Body Ratio: 94.27%Os & Processor FeaturesOperating SystemAndroid 14Processor BrandSnapdragonProcessor Type8s Gen3Processor CoreOcta CorePrimary Clock Speed3 GHzSecondary Clock Speed2.8 GHzTertiary Clock Speed2 GHzOperating Frequency2G GSM: B2/B3/B5/B8, 3G WCDMA: B1/B2/B4/B5/B6/B8/B19, 4G LTE TDD: B38/B40/B41/B42/B48, 4G LTE FDD: B1/B2/B3/B4/B5/B7/B8/B18/B19/B20/B26/B28/B66, 5G SA: n1/n2/n3/n5/n7/n8/n20/n28/n38/n40/n41/n48/n66/n77/n78, 5G NSA: n1/n3/n5/n7/n8/n20/n28/n38/n40/n41/n48/n66/n77/n78Memory & Storage FeaturesInternal Storage256 GBRAM12 GBCall Log MemoryYesCamera FeaturesPrimary Camera AvailableYesPrimary Camera50MP (OIS) + 8MPPrimary Camera FeaturesDual Camera Setup: 50MP OIS Dual Rear Camera (f/1.59 ApertureSecondary Camera AvailableYesSecondary Camera20MP Front CameraSecondary Camera FeaturesFront Camera Setup: 20MP (Features: Portrait Mode, Screen Ringlight, Front Video Recording, Night Mode, Selfie Timer, Voice Shutter, Palm Shutter, Timed Burst, Panorama Selfies, Short Film, Kaleidoscope, Timelapse Selfie)FlashRear: Ring FlashHD RecordingYesFull HD RecordingYesVideo RecordingYesVideo Recording ResolutionRear Main Camera Video: 4K (at 60 fps), 4K (at 30 fps), 1080p (at 60 fps), 1080p (at 30 fps), 720p (at 30 fps)|Front Camera: 1080p (at 60 fps), 1080p (at 30 fps), 720p (at 30 fps)Digital ZoomUpto 10XImage EditorYesDual Camera LensPrimary CameraCall FeaturesCall Wait/HoldYesConference CallYesHands FreeYesCall DivertYesPhone BookYesCall TimerYesSpeaker PhoneYesCall RecordsYesConnectivity FeaturesNetwork Type2G, 3G, 4G, 4G VOLTE, 5GSupported Networks4G LTE, 4G VoLTE, 5G, GSM, WCDMAInternet Connectivity5G, 4G, 3G, Wi-Fi, EDGE, GPRS3GYesGPRSYesMicro USB PortYesMicro USB VersionUSB Type CBluetooth SupportYesBluetooth Versionv5.4Wi-FiYesWi-Fi VersionWi-Fi 6Wi-Fi HotspotYesMini HDMI PortNoNFCYesUSB TetheringYesInfraredYesUSB ConnectivityYesEDGEYesMap SupportGoogle MapsGPS SupportYesOther DetailsSmartphoneYesTouchscreen TypeCapacitiveSIM SizeNano SimUser InterfaceHyper OS (Based on Android 14)Instant MessageYesRemovable BatteryNoMMSYesSMSYesKeypadNoVoice InputYesPredictive Text InputYesSensorsAmbient Light Sensor, Proximity Sensor, Accelerometer, Gyroscope, In-Display Fingerprint Sensor, E-Compass, IR BlasterBrowserChromeOther FeaturesIP64 Protection, UFS 4.0GPS TypeGPS, AGPS, GLONASS, GALILEO, BEIDOUMultimedia FeaturesFM RadioNoFM Radio RecordingNoBattery & Power FeaturesBattery Capacity5000 mAhBattery TypeLithium PolymerDimensionsWidth74.4 mmHeight160.5 mmDepth7.8 mmWeight179 gWarrantyWarranty Summary1 Year Manufacturer Warranty for Phone and 6 Months Warranty for In the Box AccessoriesDomestic Warranty1 YearRead MoreBuy Together and Save upto 5%POCO F6 5G (Titanium, 256 GB)4.3(7,417)‚Çπ23,999‚Çπ35,99933% offMicvir Back Cover for Poco F6 5G4(202)‚Çπ160‚Çπ1695% offSpecial price if bought with this itemKWINE CASE Edge To Edge Tempered Glass for POCO F6 5G3.8(257)‚Çπ179‚Çπ1895% offSpecial price if bought with this item1 Item‚Çπ23,9992 Add-ons‚Çπ339Total‚Çπ24,338Add 3 Items to CartRatings & ReviewsRate Product4.3‚òÖ7,417 Ratings &732 Reviews5‚òÖ4‚òÖ3‚òÖ2‚òÖ1‚òÖ4,7581,5174311665453.8Camera3.8Battery4.4Display4.1Design+ 1635Terrific purchaseI am writing this after 1 month of usagePerformance:- Snapdragon 8sGen3 is really good üëç runs everything you throw at it like emulator games at 4X resolutions like RDR , NFS and Assassins Creed Rogue or BGMI like native playstore games at 90fps constant. If you need more performance , better ui than hyperOS then go for Custom ROMs.Battery üîã:- Battery Backup is 5-6 hours with mixed usage... not satisfied with the battery life POCO does need to optimise 8sgen3 cause it is hogging power a...READ MOREShabi AbbasCertified Buyer, Prayagraj10 months ago23027PermalinkReport Abuse5Super!Great üëçREAD MOREMuzamil KumarCertified Buyer, BadgamJun, 2024635144PermalinkReport Abuse4Good quality productHyperOs needs to be well optimized for the new processor Battery life is average at this moment needs software optimisationREAD MOREVivek BCertified Buyer, BengaluruJun, 2024569PermalinkReport Abuse4Very GoodJust received the product, will review soon.Looks good , build quality seems fairBuying reason should be Snapdragon 8 gen 3 only.PROS:No lags , smooth , fast video exports.Superb DisplaySquare flat screen phone with gorilla glass victusCONS:heating even in daily task, I don't game.Average camera. Video recording is good.MIUI software not up to mark , loaded with bloatware which can be uninstalled.No always on display, AOD turn off in 20 second. So it's not AOD.Updates:  remove ...READ MORERALS JOSECertified Buyer, ChelamattomMay, 2024502174PermalinkReport Abuse4Good choiceThis phone is overall good. I mainly buy it to play bgmi but bgmi 90 fps is not unlocked yet in this device. As my gaming experience in 60 fps. It's good. Gaming is smooth and bgmi give constant 55-60fps . Device heats quite much after long gaming sessions but it also cool down quickly. Camera is oka oka. I haven't clicked many images because I'm not photogenic. Display is veryyy beautiful and colors are crisp. Only disappointment was it's battery I just bought it since 5-6 days but I have...READ MOREShubham PandeyCertified Buyer, VaranasiJun, 20249025PermalinkReport Abuse5Classy productBest gaming phone under 30k.READ MOREGolden SiddiQuiCertified Buyer, BagnanMay, 20246214PermalinkReport Abuse5ExcellentExcellent Mobile at this price, Game Centric, and Multimedia consumption is AWESOMEREAD MOREYuvraj GandhelCertified Buyer, GunderdehiJun, 20247220PermalinkReport Abuse5Perfect product!Battery need optimization and camera also want ,some times camera capture better images. Performance , display is much better than other in the segment for gaming.READ MOREAdarsh PvCertified Buyer, OlavannaJun, 2024172PermalinkReport Abuse5Must buy!1.Very bad battery,2.heat immediately if u play any game,3.otherwise outstanding performance..READ MOREchandra sekarCertified Buyer, Chennai8 months ago70PermalinkReport Abuse5Worth every pennyBeast in performance. Worth for 30k . Good camera, flawless processor nd amazing speed. Display gives premium feel. MI Gallery app causes some heat nd battery drain but barring that great phone. 5/5Best in the segment compared to rival phones .READ MOREAnandCertified Buyer, ChennaiJun, 20247022PermalinkReport Abuse+All 732 reviewsQuestions and AnswersQ:Is there DOLBY ATMOS features are available in this phone?A:yesAnonymousCertified Buyer9918Report AbuseQ:Mi dailer he ya google dailer?A:MI DiallerahsanCertified Buyer9019Report AbuseQ:Any extra motherboard in boxA:NoAnonymousCertified Buyer297101Report AbuseRead other answersQ:Is this curved display mobileA:No this mobile has flat displayN B S VenkateshCertified Buyer172Report AbuseQ:will it support 120 fps in pubgA:Bgmi has only 90 fps option. When bgmi will give 120 fps it will definitely supportAnonymousCertified Buyer81Report AbuseQ:Where is fingerprint side ya display?A:displayAnand ShekhawatCertified Buyer90Report AbuseQ:Which is better..,Poco x6 pro or poco f6?A:F6 obviously, has a better camera, and better SoC. Don't go for antutu or any other benchmarks, F6 has better in hand feel, is light weight. And very fast even in HyperOS. Imagine on AOSP ROMs.Yash ChandrawanshiCertified Buyer162Report AbuseQ:In display PingerprintA:Yesss it's in display pingerprintüòâAnonymousCertified Buyer111Report AbuseQ:Is call recording feature available?A:Yes availablesandeep mCertified Buyer80Report AbuseQ:Does it have wireless chargingA:No.It doesn't,However it supports wired charging up to fast as 90 Watts ,And it comes with a 120W charger in the box.Midhun MBCertified Buyer70Report AbuseRead other answersAll questions+Safe and Secure Payments.Easy returns.100% Authentic products.You might be interested inPower BanksMin. 50% OffShop NowWired EarphonesMin. 50% OffShop NowMemory CardsMin. 50% OffShop NowWall ChargersMin. 50% OffShop NowTop Stories:Brand DirectoryMOST SEARCHED IN Mobiles & Accessories:GIONEE G4HTC DESIRE 820 PRICEMICROMAX UNITE 2 PRICE IN INDIAMICROMAX UNITE 3 PRICE IN INDIAPHONE COVERS ONLINESELFIE STICK PRICE IN INDIAHTC PRICEINTEX MOBILE PRICESMOBILE PRICE IN INDIANOKIAMOBILENEW SMARTPHONES IN INDIA 2015MI2 MOBILESAMSUNG GALAXY NOTE 3 PRICE IN INDIASAMSUNG DUOS 2 PRICEGALAXY S4 PRICE IN INDIASONY MDR-AS200SONY SBH20XPERIA M4SONY XPERIA ZR PRICE IN INDIAYUREKAGIONEE S5.5 PRICE IN INDIAHTC 620GIVOOMI ME3MI MIX 2MICROMAX DUAL 5 PRICEMOTO Z PLUS MOBILEBEST MICROMAX PHONEBEST CELL PHONE UNDER 15000SAMSUNG A5 PRICE IN INDIAABOUTContact UsAbout UsCareersFlipkart StoriesPressCorporate InformationGROUP COMPANIESMyntraCleartripShopsyHELPPaymentsShippingCancellation & ReturnsFAQCONSUMER POLICYCancellation & ReturnsTerms Of UseSecurityPrivacySitemapGrievance RedressalEPR ComplianceMail Us:Flipkart Internet Private Limited, \n",
      " Buildings Alyssa, Begonia & \n",
      " Clove Embassy Tech Village, \n",
      " Outer Ring Road, Devarabeesanahalli Village, \n",
      " Bengaluru, 560103, \n",
      " Karnataka, India\n",
      "SocialRegistered Office Address:Flipkart Internet Private Limited, \n",
      " Buildings Alyssa, Begonia & \n",
      " Clove Embassy Tech Village, \n",
      " Outer Ring Road, Devarabeesanahalli Village, \n",
      " Bengaluru, 560103, \n",
      " Karnataka, India \n",
      " CIN : U51109KA2012PTC066107 \n",
      " Telephone: 044-45614700 / 044-67415800\n",
      "Become a SellerAdvertiseGift CardsHelp Center¬© 2007-2025 Flipkart.comBack to top   \n",
      " \n",
      "\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c86e6a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"can you answer this {question} based on this {text}. Only answer based on given text and don't assume anything on your own.\",\n",
    "    input_variables=[\"question\",\"text\"]\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "text = chain.invoke({\"question\":\"Can you tell me about processor of this smartphone\",\n",
    "              \"text\" : docs[0].page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "94e91b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The processor of the POCO F6 5G smartphone is the Snapdragon 8s Gen 3 processor. It features a powerful 3.0 GHz CPU and a 4 nm TSMC production technique, which achieves over 1.5 million AnTuTu points. The architecture of the Snapdragon 8s Gen 3 is shared with the 8 Gen 3, including the modem, RAM, display, and ISP. The POCO Ice-Loop System efficiently cools the system, and AI rendering and performance scheduling improve the responsiveness and visuals of games. The processor is also supported by 12 GB LPDDR5X RAM and up to 512 GB UFS 4.0 storage.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d0d244",
   "metadata": {},
   "source": [
    "# Length Based Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee53729",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Does not see linguistic structure, not grammer, not meaning of text. \n",
    "## Text is cutting between words, paragraph abruptly. \n",
    "## This can lead to chunks not capturing complete meaning and can lead to bad chunks.add()\n",
    "## Basically we are loosing context mid-way which is harful\n",
    "\n",
    "## Objective is to split text into smaller units that are contextually and semantically independent\n",
    "## of each other with each having proper linguistic structure and grammer\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"/Users/mukulagarwal/Desktop/Projects/langchain/rag-for-nlp.pdf\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap = 40,\n",
    "    separator= ''\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f75ea6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "29782d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval-Augmented Generation for\n",
      "Knowledge-Intensive NLP Tasks\n",
      "Patrick Lewis†‡, Ethan Perez⋆,\n",
      "Aleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†,\n",
      "Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela†\n",
      "†Facebook AI Research; ‡University\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1cedefc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ela†\n",
      "†Facebook AI Research; ‡University College London; ⋆New York University;\n",
      "plewis@fb.com\n",
      "Abstract\n",
      "Large pre-trained language models have been shown to store factual knowledge\n",
      "in their parameters, and achieve state-of-the-art results when ﬁne-tuned on down-\n",
      "stream NLP tasks. However, their ability\n"
     ]
    }
   ],
   "source": [
    "print(chunks[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4cc486e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream NLP tasks. However, their ability to access and precisely manipulate knowl-\n",
      "edge is still limited, and hence on knowledge-intensive tasks, their performance\n",
      "lags behind task-speciﬁc architectures. Additionally, providing provenance for their\n",
      "decisions and updating their world knowledge remain\n"
     ]
    }
   ],
   "source": [
    "print(chunks[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1a774463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.21',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2021-04-13T00:48:38+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2021-04-13T00:48:38+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': '/Users/mukulagarwal/Desktop/Projects/langchain/rag-for-nlp.pdf',\n",
       " 'total_pages': 19,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e94b2a",
   "metadata": {},
   "source": [
    "# Text Structure based text splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6f27d578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Text inherently follows a structure ==> Paragraph, Sentence, Words\n",
    "## Popular == RecursiveCharacterSplitter() --> Popular ones\n",
    "\n",
    "## Paragraph - \\n\\n\n",
    "## Line space/Sentence - \\n\n",
    "## Words -- ' '\n",
    "## character -- '' \n",
    "\n",
    "text = \"\"\"\n",
    "Google opens up its AI language model PaLM to challenge OpenAI and GPT-3 Google \n",
    "offers developers access to one of its most advanced AI language models: PaLM. The search \n",
    "giant is launching an API for PaLM alongside a number of AI enterprise tools it says will \n",
    "help businesses generate text, images, code, videos, audio, and more from simple natural \n",
    "language prompts. \n",
    "\n",
    "PaLM is a large language model, or LLM, similar to the GPT series created \n",
    "by OpenAI or Meta's LLaMA family of models. Google first announced PaLM in April 2022. Like \n",
    "other LLMs, PaLM is a flexible system that can potentially carry out all sorts of text \n",
    "generation and editing tasks. You could train PaLM to be a conversational chatbot like \n",
    "ChatGPT, for example, or you could use it for tasks like summarizing text or even writing code. \n",
    "(It's similar to features Google also announced today for its Workspace apps like Google Docs \n",
    "and Gmail.)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 10\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(text)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4fc9280b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'giant is launching an API for PaLM alongside a number of AI enterprise tools it says will'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90203704",
   "metadata": {},
   "source": [
    "# Document Structure based text splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2ec48239",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you have  a text like a code that is organised in a different format like classes, functions\n",
    "## Here you use different specific keywords like for example a python code \\nclass, \\ndef, \\n\\tdef\n",
    "## Similarly this same thing applies to MarkDown text\n",
    "\n",
    "## Extends Idea of Text Based splitter to other docs likr python code, markdown etc.. where we seperators. \n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "text = \"\"\"\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader=DirectoryLoader(\"/Users/mukulagarwal/Desktop/Projects/langchain\",glob=\"./*.txt\",loader_cls=TextLoader)\n",
    "docs=loader.load()\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=250,\n",
    "    chunk_overlap=25\n",
    ")\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings = [doc.page_content for doc in new_docs]\n",
    "\"\"\"\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size = 400,\n",
    "    chunk_overlap = 18\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1eea7e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a36503c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loader=DirectoryLoader(\"/Users/mukulagarwal/Desktop/Projects/langchain\",glob=\"./*.txt\",loader_cls=TextLoader)\n",
      "docs=loader.load()\n",
      "text_splitter=RecursiveCharacterTextSplitter(\n",
      "    chunk_size=250,\n",
      "    chunk_overlap=25\n",
      ")\n",
      "new_docs = text_splitter.split_documents(documents=docs)\n",
      "doc_strings = [doc.page_content for doc in new_docs]\n"
     ]
    }
   ],
   "source": [
    "print(chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1ae0f778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\n\\n</think>\\n\\nAI, or Artificial Intelligence, refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. It encompasses various technologies like machine learning, natural language processing, and robotics. AI systems can perform tasks such as problem-solving, decision-making, speech recognition, and more.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 6, 'total_tokens': 70, 'completion_time': 0.232727273, 'prompt_time': 0.000104888, 'queue_time': 0.053838122, 'total_time': 0.232832161}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--0715d8f6-23f7-4309-ad0c-b5d1c251d25a-0', usage_metadata={'input_tokens': 6, 'output_tokens': 64, 'total_tokens': 70})"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model = \"deepseek-r1-distill-llama-70b\")\n",
    "\n",
    "model.invoke(\"what is ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0f17d64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\nOkay, so I need to figure out how a study schedule is helpful. Hmm, I remember that when I was in school, my teachers always told us to make study schedules, but I never really thought about why. Let me try to break this down.\\n\\nFirst, I think about time management. When I have a lot of work, like during exams, it's easy to get overwhelmed. Maybe a schedule helps me organize my time better. Instead of cramming everything the night before, I can spread it out. That way, I don't get too stressed, and I can actually study more effectively.\\n\\nThen there's the idea of priorities. If I make a schedule, I can decide what's most important to study each day. For example, if I have a math test coming up, I can allocate more time to math than to other subjects. This helps me focus on what really needs attention.\\n\\nI also remember that when I study without a plan, I often end up procrastinating. I might spend too much time on one subject and not enough on another. A schedule could help me avoid that by setting specific times for each subject, keeping me on track.\\n\\nConsistency is another thing. If I study a little bit each day instead of trying to do everything at once, it might help me remember things better. It's like how sometimes you learn a new skill better by practicing a bit each day rather than all at once. So, a schedule could make my study sessions more consistent.\\n\\nBreaking tasks into smaller parts is something I've heard about. When I have a big project or a lot of material to cover, it can feel really daunting. A study schedule could help me break it down into smaller, manageable chunks. That makes the task less scary and more achievable.\\n\\nSetting goals is important too. If I know I have to finish a certain number of chapters by the end of the week, it gives me a clear target. Without a schedule, I might not have a sense of direction, leading to wasted time.\\n\\nAccountability is another factor. When I write down my study plan, it's like making a commitment to myself. It's easier to stick to it because I can see it laid out in front of me. Without that, it's too easy to put things off.\\n\\nReducing stress is a big one. I remember feeling really anxious before exams because I wasn't prepared. If I have a schedule, I can prepare gradually, which might make me feel more in control and less stressed. Plus, knowing that I've covered all the material can boost my confidence.\\n\\nFlexibility is something I didn't think about at first. I guess even though a schedule is structured, I can still adjust it if something comes up. If I need to spend more time on a particular topic, I can move things around without getting off track completely.\\n\\nAvoiding burnout is important. If I try to study for hours without a break, I get tired and can't focus. A schedule can include breaks and downtime, which helps me maintain my energy levels and stay productive.\\n\\nImproving retention is key. When I review material regularly, it's easier to remember. A study schedule can ensure that I go over my notes consistently, which helps in retaining the information better than trying to cram everything in one session.\\n\\nTracking progress is another benefit. By following a schedule, I can see how much I've accomplished each day. That sense of progress can be motivating. It's like checking things off a to-do list, which feels satisfying.\\n\\nEnhancing discipline is something I struggle with. Without a routine, it's easy to get distracted. A study schedule forces me to create a routine, which can improve my overall discipline and help me in other areas of life too.\\n\\nLastly, better work-life balance. I don't want to study all the time and neglect other parts of my life. A schedule can allocate specific times for studying and other activities, making sure I have time for everything without feeling overwhelmed.\\n\\nSo, putting it all together, a study schedule helps with time management, prioritization, avoiding procrastination, maintaining consistency, breaking tasks into smaller parts, setting goals, accountability, reducing stress, flexibility, avoiding burnout, improving retention, tracking progress, enhancing discipline, and achieving a better work-life balance. It seems like using a study schedule can really make a big difference in how effectively I study and manage my time.\\n</think>\\n\\nA study schedule offers numerous benefits that enhance learning and time management. Here's a concise summary of how it is helpful:\\n\\n1. **Time Management**: Organizes study sessions to prevent cramming and reduce stress by spreading tasks over time.\\n\\n2. **Prioritization**: Allocates more time to important or challenging subjects, ensuring focused study.\\n\\n3. **Procrastination Prevention**: Sets specific times for each subject, keeping studying on track and avoiding distractions.\\n\\n4. **Consistency**: Encourages regular study sessions, aiding better retention and understanding.\\n\\n5. **Task Breakdown**: Divides large tasks into manageable parts, making them less daunting.\\n\\n6. **Goal Setting**: Provides clear targets, giving direction and motivation.\\n\\n7. **Accountability**: Acts as a commitment, helping to adhere to study plans.\\n\\n8. **Stress Reduction**: Gradual preparation boosts confidence and control.\\n\\n9. **Flexibility**: Allows adjustments for unexpected events without derailing progress.\\n\\n10. **Burnout Avoidance**: Includes breaks to maintain energy and focus.\\n\\n11. **Improved Retention**: Regular review of material enhances memory and understanding.\\n\\n12. **Progress Tracking**: Offers a sense of accomplishment, motivating continued effort.\\n\\n13. **Enhanced Discipline**: Establishes a routine, improving overall self-discipline.\\n\\n14. **Work-Life Balance**: Allocates time for both study and other activities, preventing overwhelm.\\n\\nIn essence, a study schedule is a powerful tool that fosters effective learning, reduces stress, and promotes a balanced lifestyle.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1200, 'prompt_tokens': 8, 'total_tokens': 1208, 'completion_time': 5.057953557, 'prompt_time': 0.000141268, 'queue_time': 0.057126762, 'total_time': 5.058094825}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--a035fb1d-b423-4af7-b84d-9ec89b67e764-0', usage_metadata={'input_tokens': 8, 'output_tokens': 1200, 'total_tokens': 1208})"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"How is study schedule helpful\",\n",
    "    input_variables=[]\n",
    ")\n",
    "\n",
    "prompt = prompt.invoke({})\n",
    "\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7ed2efd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\n\\n</think>\\n\\nSure! Could you clarify what you'd like me to build? For example:\\n\\n- A website\\n- A mobile app\\n- A chatbot\\n- A piece of code\\n- A design concept\\n- Something else?\\n\\nLet me know, and I’ll help you out!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 7, 'total_tokens': 68, 'completion_time': 0.252265389, 'prompt_time': 0.000315016, 'queue_time': 0.055618594, 'total_time': 0.252580405}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--a4781f20-2532-4260-8439-22acc902cae5-0', usage_metadata={'input_tokens': 7, 'output_tokens': 61, 'total_tokens': 68})"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Build one for me\",\n",
    "    input_variables=[]\n",
    ")\n",
    "\n",
    "prompt = prompt.invoke({})\n",
    "\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "82807e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\nOkay, so I need to figure out how a study schedule is helpful. I remember the user gave a detailed answer before, but I need to think through this as if I'm trying to understand it for the first time.\\n\\nFirst, I guess a study schedule helps with time management. Without a plan, it's easy to procrastinate or not know where to start. If I have a schedule, I can allocate specific times to each subject or task, making sure I cover everything without running out of time.\\n\\nWait, but how exactly does that help? Maybe it breaks things down into smaller chunks. If I have a big exam coming up, studying everything at once is overwhelming. A schedule could spread out the study sessions, making each one manageable. That way, I don't cram all the studying into one night, which isn't effective.\\n\\nAlso, consistency might be a factor. If I study a little every day, I'm more likely to retain the information than if I study a lot once a week. It helps build a routine, which can make studying a habit. That could lead to better performance because I'm consistently reviewing the material.\\n\\nAnother thought: a schedule can help prioritize tasks. If I have multiple subjects or assignments, a schedule ensures I don't neglect any. I can assign more time to weaker areas and less to stronger ones, balancing my study time effectively.\\n\\nI wonder about reducing stress. Without a plan, the pressure to study everything might be overwhelming. A schedule provides a clear path, so I know exactly what to do each day. That structure might make me feel more in control and less anxious.\\n\\nIt probably also helps with avoiding procrastination. When I have specific times set aside for studying, I'm more likely to stick to them rather than putting things off until the last minute. Procrastination can lead to rushed and less effective studying, so a schedule acts as a commitment device.\\n\\nSetting goals is another aspect. A study schedule allows me to set both short-term and long-term goals. Each study session can have specific objectives, which helps me track my progress. Meeting these small goals can be motivating and build confidence.\\n\\nWait, but what about flexibility? Sometimes unexpected things come up, and a rigid schedule might cause stress if I can't stick to it. Maybe the key is to have a structured yet flexible plan that allows for adjustments without derailing the entire schedule.\\n\\nAlso, a schedule can help with review and practice. Spacing out study sessions over time can improve long-term retention through the spacing effect. Instead of cramming, which leads to short-term memory, spaced practice helps move information into long-term memory.\\n\\nAnother point is balancing study with other activities. A good schedule includes breaks, exercise, and leisure time. This balance is crucial for maintaining mental and physical health, which in turn supports better academic performance.\\n\\nI should also consider how a schedule teaches time management skills. For students, especially, learning to prioritize and organize time is an important life skill that goes beyond academics. It helps in future careers and personal life.\\n\\nBut does everyone benefit from a study schedule? I think so, but the way each person uses it might vary. Some might need more structure, while others prefer a looser plan. The key is to find a balance that works for the individual.\\n\\nIn summary, a study schedule is helpful for organizing time, breaking tasks into manageable parts, building consistency, prioritizing, reducing stress, avoiding procrastination, setting goals, allowing for spaced practice, balancing life activities, and developing time management skills. These factors collectively contribute to more effective studying and better academic outcomes.\\n</think>\\n\\nA study schedule is a powerful tool that offers numerous benefits, enhancing both academic performance and overall well-being. Here's a structured overview of its helpfulness:\\n\\n1. **Time Management**: A schedule helps allocate specific times to different subjects or tasks, ensuring efficient use of time and preventing procrastination. It breaks down large tasks into manageable chunks, avoiding overwhelm and promoting steady progress.\\n\\n2. **Consistency and Habit Formation**: Regular study sessions foster a routine, making studying a habit. This consistency aids in information retention and improves academic performance.\\n\\n3. **Prioritization**: By allocating more time to weaker areas and less to stronger ones, a schedule ensures balanced study time, preventing neglect of any subject.\\n\\n4. **Stress Reduction**: A clear plan reduces anxiety by providing a structured path, making the student feel more in control and less overwhelmed.\\n\\n5. **Procrastination Avoidance**: Scheduled study times act as a commitment, discouraging last-minute cramming and promoting effective studying.\\n\\n6. **Goal Setting**: The schedule allows for setting short-term and long-term goals, with each session having specific objectives. Achieving these goals boosts motivation and confidence.\\n\\n7. **Flexibility**: While structured, a good schedule remains adaptable, allowing for adjustments without causing stress.\\n\\n8. **Spaced Practice**: Spreading study sessions over time enhances long-term retention through the spacing effect, moving information into long-term memory.\\n\\n9. **Balance with Other Activities**: Incorporating breaks, exercise, and leisure ensures mental and physical health, supporting overall well-being and academic success.\\n\\n10. **Life Skill Development**: It teaches crucial time management skills, benefiting future careers and personal life.\\n\\nIn essence, a study schedule is a versatile tool that, when tailored to individual needs, significantly enhances learning effectiveness and personal development.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1089, 'prompt_tokens': 13, 'total_tokens': 1102, 'completion_time': 4.389398005, 'prompt_time': 0.000412846, 'queue_time': 0.054837974, 'total_time': 4.389810851}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--bdc88137-2699-4a89-bd5c-588124db3ab0-0', usage_metadata={'input_tokens': 13, 'output_tokens': 1089, 'total_tokens': 1102})"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [(\"system\",\"you are a helpful assistant\"),\n",
    "    (\"human\",\"How is study schedule helpful\")]\n",
    ")\n",
    "\n",
    "prompt = prompt.invoke({})\n",
    "\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "16d9a5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\n\\n</think>\\n\\nSure! Could you clarify what you'd like me to build? For example:\\n\\n- A website\\n- A mobile app\\n- A chatbot\\n- A piece of software\\n- A game\\n- Something else?\\n\\nLet me know, and I’ll help you get started!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 7, 'total_tokens': 68, 'completion_time': 0.227147179, 'prompt_time': 0.000142998, 'queue_time': 0.057827781, 'total_time': 0.227290177}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--afda36a5-4f59-4fc8-a88e-f8ce03ce7457-0', usage_metadata={'input_tokens': 7, 'output_tokens': 61, 'total_tokens': 68})"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate(\n",
    "    [(\"human\",\"Build one for me\")]\n",
    ")\n",
    "\n",
    "prompt = prompt.invoke({})\n",
    "\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b2f343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e674cc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mukulagarwal/Desktop/Projects/langchain/langchain_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader \n",
    "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEndpointEmbeddings(\n",
    "    repo_id= \"sentence-transformers/all-mpnet-base-v2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abada695",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.embed_query(\"what is langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7654cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1115733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'black hole',\n",
       " 'detail_explanations': \"Black holes are among the most fascinating and mysterious objects in the universe. As an astrophysicist, I'd be happy to delve into the details of black holes.\\n\\n**What is a Black Hole?**\\n\\nA black hole is a region in space where the gravitational pull is so strong that nothing, including light, can escape. It is formed when a massive star collapses in on itself and its gravity becomes so strong that it warps the fabric of spacetime around it.\\n\\n**How is a Black Hole Formed?**\\n\\nA black hole is formed when a massive star runs out of fuel and dies. If the star is massive enough (at least 3-4 times the size of the sun), its gravity will collapse the star in on itself, causing a supernova explosion. If the star is even more massive (at least 10-20 times the size of the sun), its gravity will be so strong that it will not only collapse the star but also create a singularity, a point of infinite density and zero volume.\\n\\n**Characteristics of a Black Hole**\\n\\nA black hole has several characteristics that make it unique:\\n\\n1. **Event Horizon**: The event horizon is the point of no return around a black hole. Once something crosses the event horizon, it is trapped by the black hole's gravity and cannot escape.\\n2. **Singularity**: The singularity is the point at the center of a black hole where the density and curvature of spacetime are infinite.\\n3. **Mass**: The mass of a black hole is equal to its total energy.\\n4. **Spin**: Black holes can spin around their axis, which affects the way they distort spacetime.\\n5. **Charge**: Black holes can have an electric charge, which affects their behavior in the presence of other charged objects.\\n\\n**Types of Black Holes**\\n\\nThere are four types of black holes, each with different properties:\\n\\n1. **Stellar Black Holes**: These are the smallest and most common type of black hole, formed from the collapse of individual stars.\\n2. **Supermassive Black Holes**: These are found at the centers of galaxies and have masses millions or even billions of times that of the sun.\\n3. **Intermediate-Mass Black Holes**: These are black holes with masses that fall between those of stellar and supermassive black holes.\\n4. **Primordial Black Holes**: These are hypothetical black holes that may have formed in the early universe before the first stars formed.\\n\\n**Properties of Black Holes**\\n\\nBlack holes have several properties that make them interesting:\\n\\n1. **Gravitational Pull**: The gravitational pull of a black hole is so strong that it warps spacetime around it.\\n2. **Time Dilation**: Time dilation occurs near a black hole, causing time to pass slower for objects near the event horizon than for objects farther away.\\n3. **Frame-Dragging**: Frame-dragging occurs near a rotating black hole, causing spacetime to drag along with the rotation of the black hole.\\n4. **Hawking Radiation**: Black holes emit radiation, known as Hawking radiation, due to quantum effects near the event horizon.\\n\\n**Detection of Black Holes**\\n\\nBlack holes are difficult to detect directly, but their presence can be inferred through various methods:\\n\\n1. **X-rays and Gamma Rays**: Telescopes can detect X-rays and gamma rays emitted by hot gas swirling around black holes.\\n2. **Radio Waves**: Radio telescopes can detect radio waves emitted by matter as it spirals into a black hole.\\n3. **Gravitational Waves**: The detection of gravitational waves by LIGO and VIRGO collaboration in 2015 provided strong evidence for the existence of black holes.\\n4. **Star Motions**: Astronomers can observe the motions of stars near a suspected black hole to determine if they are being affected by its gravity.\\n\\n**Conclusion**\\n\\nBlack holes are fascinating objects that continue to capture the imagination of scientists and the public alike. Their strong gravity, warping of spacetime, and unique properties make them an important area of study in astrophysics. While we have learned much about black holes, there is still much to be discovered, and ongoing research is helping us better understand these enigmatic objects.\",\n",
       " 'summary': \"Black holes are among the most intriguing and mysterious objects in the universe. They are regions of space where the gravitational pull is so strong that nothing, including light, can escape. Here's a summary of their formation, characteristics, and types:\\n\\n**Formation of a Black Hole**\\n\\nA black hole is formed when a massive star collapses in on itself, creating an incredibly strong gravitational field. This collapse causes the star's core to become increasingly dense and hot, eventually forming a singularity. The point of no return around a black hole is called the event horizon, where anything that crosses it is trapped by the black hole's gravity.\\n\\n**Characteristics of a Black Hole**\\n\\nBlack holes have several unique characteristics, including:\\n\\n1. **Mass**: The strength of their gravitational pull is determined by their mass.\\n2. **Spin**: Black holes can rotate, affecting the way they distort spacetime around them.\\n3. **Charge**: Black holes can have an electric charge, affecting their interaction with other charged objects.\\n4. **Event Horizon**: The point of no return around a black hole.\\n\\n**Types of Black Holes**\\n\\nThere are four types of black holes:\\n\\n1. **Stellar Black Holes**: Formed from the collapse of individual stars.\\n2. **Intermediate-Mass Black Holes**: Have masses between those of stellar and supermassive black holes.\\n3. **Supermassive Black Holes**: Found at the centers of galaxies, with masses millions or even billions of times that of the sun.\\n4. **Primordial Black Holes**: Hypothetical black holes that may have formed in the early universe.\\n\\n**Observational Evidence for Black Holes**\\n\\nWhile black holes themselves are invisible, their presence can be inferred from the effects they have on the surrounding environment, such as:\\n\\n1. **X-rays and Gamma Rays**: Telescopes can detect X-rays and gamma rays emitted by hot gas swirling around black holes.\\n2. **Radio Waves**: Radio telescopes can detect radio waves emitted by matter as it spirals into a black hole.\\n3. **Star Motions**: The motion of stars near a suspected black hole can be used to infer the presence of a massive, unseen object.\\n4. **Gravitational Waves**: The detection of gravitational waves by LIGO and VIRGO have provided strong evidence for the existence of black holes.\\n\\nThe study of black holes is an active area of research, with scientists using various techniques to study these enigmatic objects.\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel, RunnableBranch, RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser\n",
    "from pydantic import BaseModel\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "class OutputStr(BaseModel):\n",
    "    topic : str\n",
    "    explanation:str\n",
    "    summary:str\n",
    "\n",
    "pyd_parser = PydanticOutputParser(pydantic_object=OutputStr)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "prompt1 = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\",\"You are expert astrophysician.\"),\n",
    "        (\"human\",\"Explain me about {topic} in detail\")\n",
    "    ],\n",
    "    input_variables = [\"topic\"]\n",
    ")\n",
    "\n",
    "prompt2 = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"human\",\"summarize the below text in less than 300-500 words\\n{text}\")\n",
    "    ],\n",
    "    input_variables = [\"text\"]\n",
    ")\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "parallel_chain = RunnableParallel(\n",
    "    {\n",
    "        \"topic\" : RunnableLambda(lambda x : x['topic']),\n",
    "        \"detail_explanations\":prompt1 | llm | parser,\n",
    "        \"summary\" : prompt1 | llm | parser | prompt2 | llm | parser\n",
    "    }\n",
    ")\n",
    "\n",
    "# prompt3 = ChatPromptTemplate(\n",
    "#     messages=[\n",
    "#         (\"system\",\"{format_instructions}\"),\n",
    "#         (\"human\",\"Return topic, detailed explanation and summary \\ndetailed_explanations: {detail_explanations}\\nSummary: {summary}\")\n",
    "#     ],\n",
    "#     input_variables = [\"text\"],\n",
    "#     partial_variables = {\"format_instructions\":pyd_parser.get_format_instructions()}\n",
    "    \n",
    "# )\n",
    "# \n",
    "# final_chain = parallel_chain | prompt3 | llm | pyd_parser\n",
    "\n",
    "answer = parallel_chain.invoke({\"topic\":\"black hole\"})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abd395be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Here is a JSON instance that conforms to the provided schema:\\n\\n```json\\n{\\n  \"topic\": \"Black Holes\",\\n  \"explanation\": {\\n    \"What is a Black Hole?\": \"A black hole is a region of spacetime where the gravitational pull is so strong that it warps the fabric of spacetime around it.\",\\n    \"Properties of Black Holes\": \"Black holes have several properties, including mass, charge, spin, event horizon, and singularity.\",\\n    \"Types of Black Holes\": \"There are four types of black holes: stellar, intermediate-mass, supermassive, and primordial.\",\\n    \"Formation of Black Holes\": \"Black holes form when a massive star collapses under its own gravity, creating a singularity at its center.\",\\n    \"Characteristics of Black Holes\": \"Black holes have an incredibly strong gravitational pull, no escape, no radiation, and are silent.\",\\n    \"Observational Evidence for Black Holes\": \"Black holes can be inferred from the effects they have on the surrounding environment, including star motions, X-rays, gamma rays, and gravitational waves.\",\\n    \"The Information Paradox\": \"The information paradox arises from the fact that the laws of quantum mechanics suggest that information cannot be destroyed, while the laws of general relativity suggest that anything that falls into a black hole is lost forever.\",\\n    \"Black Hole Information Paradox Resolution\": \"The information paradox is resolved through a process called \\\\\"black hole evaporation,\\\\\" where the black hole emits radiation and the information is released.\",\\n    \"Black Hole Evaporation\": \"Black holes have a finite lifetime and will eventually evaporate through Hawking radiation.\",\\n    \"Conclusion\": \"Black holes are among the most fascinating and mysterious objects in the universe, with several properties, types, and formation mechanisms.\"\\n  },\\n  \"summary\": \"Black holes are regions in space with such strong gravity that nothing, including light, can escape. They form when massive stars collapse, creating a singularity with infinite density. Black holes have mass, spin, charge, and an event horizon, beyond which nothing can escape. There are four types: stellar, intermediate-mass, supermassive, and primordial.\"\\n}\\n```\\n\\nNote that the `explanation` field is an object with multiple properties, each representing a distinct explanation or section of the text. This conforms to the schema, which specifies that the `explanation` field is an object with a title of \"Explanation\" and a type of \"string\".' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 508, 'prompt_tokens': 1600, 'total_tokens': 2108, 'completion_time': 0.677333333, 'prompt_time': 0.102368218, 'queue_time': 0.049124822, 'total_time': 0.779701551}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_8ab2e50475', 'finish_reason': 'stop', 'logprobs': None} id='run--fe2c06bb-e903-4233-9a41-c71de8fcac4c-0' usage_metadata={'input_tokens': 1600, 'output_tokens': 508, 'total_tokens': 2108}\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7126e962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Artificial Intelligence (AI)**\\n\\n**Definition:** Artificial Intelligence (AI) is the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The goal of AI is to create intelligent machines that can perform tasks that typically require human intelligence, such as learning, problem-solving, decision-making, and perception.\\n\\n**Key Characteristics:**\\n\\n1. **Machine Learning (ML):** AI systems can learn from data and improve their performance over time.\\n2. **Automation:** AI systems can perform tasks autonomously, reducing the need for human intervention.\\n3. **Adaptability:** AI systems can adapt to new situations and environments.\\n4. **Reasoning:** AI systems can reason and draw conclusions based on data and rules.\\n\\n**Types of AI:**\\n\\n1. **Narrow or Weak AI:** Designed to perform a specific task, such as image recognition or language translation.\\n2. **General or Strong AI:** A hypothetical AI system that possesses human-like intelligence and can perform any intellectual task.\\n3. **Superintelligence:** An AI system that significantly surpasses human intelligence, potentially leading to exponential growth in capabilities.\\n\\n**Applications:**\\n\\n1. **Virtual Assistants:** Siri, Alexa, Google Assistant\\n2. **Image Recognition:** Self-driving cars, facial recognition\\n3. **Natural Language Processing:** Chatbots, language translation\\n4. **Predictive Maintenance:** Predicting equipment failures\\n5. **Healthcare:** Diagnosing diseases, personalized medicine\\n\\nAs an AI/ML Engineer, I design and develop AI systems that can learn from data and improve their performance over time, enabling organizations to make informed decisions and automate tasks.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 335, 'prompt_tokens': 46, 'total_tokens': 381, 'completion_time': 0.446666667, 'prompt_time': 0.002273128, 'queue_time': 0.049800372, 'total_time': 0.448939795}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_8ab2e50475', 'finish_reason': 'stop', 'logprobs': None}, id='run--1385e5ac-f3bc-40fc-b4a5-0feba4e512d5-0', usage_metadata={'input_tokens': 46, 'output_tokens': 335, 'total_tokens': 381})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "llm.invoke([\n",
    "    SystemMessage(\"You are a AI/ML Engineer\"),\n",
    "    HumanMessage(\"Briefly explain AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fb94c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Fascinating World of Black Holes**\n",
      "\n",
      "Black holes are among the most mysterious objects in the universe, captivating scientists and the public alike. A black hole is a region in space where the gravitational pull is so strong that nothing, including light, can escape. It is formed when a massive star collapses in on itself, warping the fabric of spacetime around it.\n",
      "\n",
      "**Formation and Characteristics**\n",
      "\n",
      "The formation of a black hole occurs in four stages: massive star collapse, core collapse, singularity formation, and event horizon formation. Black holes have unique characteristics, including mass, spin, and charge, which determine their gravitational pull and interaction with other objects. There are four types of black holes: stellar, intermediate-mass, supermassive, and primordial.\n",
      "\n",
      "**Effects on Spacetime and Detection**\n",
      "\n",
      "Black holes distort spacetime in extreme ways, creating effects that can be observed, such as gravitational lensing and frame-dragging. They are difficult to detect directly, but their presence can be inferred through indirect means, including X-rays, gamma rays, radio waves, and gravitational waves.\n",
      "\n",
      "**Open Questions and Future Research**\n",
      "\n",
      "The study of black holes is an active area of research, with many questions still unanswered. Some of the open questions include the information paradox, black hole mergers, and black hole cosmology. The observation of gravitational waves from merging black holes has opened a new window into the study of these objects, and further research is needed to understand the mysteries of black holes.\n",
      "\n",
      "**Key Takeaways**\n",
      "\n",
      "- Black holes are formed when massive stars collapse in on themselves.\n",
      "- Black holes have unique characteristics, including mass, spin, and charge.\n",
      "- There are four types of black holes: stellar, intermediate-mass, supermassive, and primordial.\n",
      "- Black holes distort spacetime in extreme ways, creating effects that can be observed.\n",
      "- Black holes are difficult to detect directly, but their presence can be inferred through indirect means.\n",
      "- The study of black holes is an active area of research, with many questions still unanswered."
     ]
    }
   ],
   "source": [
    "chain =  prompt1 | llm | parser | prompt2 | llm | parser\n",
    "for token in chain.stream({\"topic\":\"black holes\"}):\n",
    "    print(token,end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc594308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "521a5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the documents\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(file_path=\"rag-for-nlp.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9baf2697",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5d93ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_spitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200, add_start_index = True)\n",
    "docs = text_spitter.split_documents(docs)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684c6cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc1e23674c44a1f8bbc01fe93cbbf69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c2024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "embed_model.embed_query(\"how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e310b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emdded_docs = embed_model.embed_documents([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "425e7f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emdded_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fd0b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14697194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "index_name = \"langchain-test-index\"  # change if desired\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71fd3588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b496b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "uuids = [str(uuid4()) for _ in range(len(docs))]\n",
    "vector_store.add_documents(documents=docs, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bb486d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs = {\"k\":3})\n",
    "docs = retriever.invoke(\"what is rag ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c97ba798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eca14a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"Based on the context given below\\n{context}\\n answer the user query: {query}\",\n",
    "    input_variables=[\"query\",\"context\"] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a226d785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is rag ? ',\n",
       " 'context': [Document(id='1a2d9b5d-d67a-45d5-9933-fcdc1d72ce3b', metadata={'author': '', 'creationdate': '2021-04-13T00:48:38+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2021-04-13T00:48:38+00:00', 'page': 16.0, 'page_label': '17', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'rag-for-nlp.pdf', 'start_index': 2357.0, 'subject': '', 'title': '', 'total_pages': 19.0, 'trapped': '/False'}, page_content='blob/master/examples/rag/README.md and an interactive demo of a RAG model can be found\\nat https://huggingface.co/rag/\\n2https://github.com/pytorch/fairseq\\n3https://github.com/huggingface/transformers\\n17'),\n",
       "  Document(id='76424d4f-175a-4489-a8ed-4865a3b8cc3b', metadata={'author': '', 'creationdate': '2021-04-13T00:48:38+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2021-04-13T00:48:38+00:00', 'page': 9.0, 'page_label': '10', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'rag-for-nlp.pdf', 'start_index': 0.0, 'subject': '', 'title': '', 'total_pages': 19.0, 'trapped': '/False'}, page_content='Broader Impact\\nThis work offers several positive societal beneﬁts over previous work: the fact that it is more\\nstrongly grounded in real factual knowledge (in this case Wikipedia) makes it “hallucinate” less\\nwith generations that are more factual, and offers more control and interpretability. RAG could be\\nemployed in a wide variety of scenarios with direct beneﬁt to society, for example by endowing it\\nwith a medical index and asking it open-domain questions on that topic, or by helping people be more\\neffective at their jobs.\\nWith these advantages also come potential downsides: Wikipedia, or any potential external knowledge\\nsource, will probably never be entirely factual and completely devoid of bias. Since RAG can be\\nemployed as a language model, similar concerns as for GPT-2 [50] are valid here, although arguably\\nto a lesser extent, including that it might be used to generate abuse, faked or misleading content in'),\n",
       "  Document(id='a8d39b4e-3ff4-4691-84f9-a461ff845d11', metadata={'author': '', 'creationdate': '2021-04-13T00:48:38+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2021-04-13T00:48:38+00:00', 'page': 7.0, 'page_label': '8', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'rag-for-nlp.pdf', 'start_index': 1603.0, 'subject': '', 'title': '', 'total_pages': 19.0, 'trapped': '/False'}, page_content='ﬂexibility to adjust the number of retrieved documents at test time, which can affect performance and\\nruntime. Figure 3 (left) shows that retrieving more documents at test time monotonically improves\\nOpen-domain QA results for RAG-Sequence, but performance peaks for RAG-Token at 10 retrieved\\ndocuments. Figure 3 (right) shows that retrieving more documents leads to higher Rouge-L for\\nRAG-Token at the expense of Bleu-1, but the effect is less pronounced for RAG-Sequence.\\n10 20 30 40 50\\nKR e t r i e v e dD o c s\\n39\\n40\\n41\\n42\\n43\\n44NQ Exact Match RAG-Tok\\nRAG-Seq\\n10 20 30 40 50\\nKR e t r i e v e dD o c s\\n40\\n50\\n60\\n70\\n80NQ Answer Recall @ K\\nRAG-Tok\\nRAG-Seq\\nFixed DPR\\nBM25\\n10 20 30 40 50\\nKR e t r i e v e dD o c s\\n48\\n50\\n52\\n54\\n56Bleu-1 / Rouge-L score\\nRAG-Tok R-L\\nRAG-Tok B-1\\nRAG-Seq R-L\\nRAG-Seq B-1\\nFigure 3: Left: NQ performance as more documents are retrieved. Center: Retrieval recall perfor-\\nmance in NQ. Right: MS-MARCO Bleu-1 and Rouge-L as more documents are retrieved.\\n5 Related Work')]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "parallel_chain = RunnableParallel(\n",
    "    {\"query\":RunnablePassthrough(),\n",
    "     \"context\": retriever}\n",
    ")\n",
    "parallel_chain.invoke(\"what is rag ? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d301262e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, RAG stands for \"Retriever-Augmented Generator\" or \"RAG model.\" It is a language model that combines the strengths of retriever models (which retrieve relevant information from a large corpus of text) and generator models (which generate text based on that information).\\n\\nFrom the text, it appears that RAG is a more controlled and interpretable language model compared to previous models like GPT-2. It is \"strongly grounded in real factual knowledge\" and is less likely to \"hallucinate\" with generations that are more factual.\\n\\nRAG can be employed in various scenarios with direct benefits to society, such as endowing it with a medical index and asking it open-domain questions on that topic, or helping people be more effective at their jobs.\\n\\nHowever, RAG also comes with potential downsides, such as the possibility of generating abuse, faked, or misleading content, similar to concerns with GPT-2.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = parallel_chain | prompt |llm | parser\n",
    "chain.invoke(\"what is rag ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21adc1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4e63a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool, StructuredTool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class MultiplyInput(BaseModel):\n",
    "    a:int = Field(strict = True, description = \"This is first number\")\n",
    "    b:int = Field(strict = True, description = \"This is second number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cb030029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_numbers(a:int,b:int) -> int:\n",
    "    return a * b\n",
    "\n",
    "multiply_tool = StructuredTool.from_function(\n",
    "        func=multiply_numbers,\n",
    "        description=\"multiply two number\",\n",
    "        args_schema=MultiplyInput,\n",
    "        name = \"multiply\" \n",
    "    )\n",
    "\n",
    "print(type(multiply_tool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd26366c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply_tool.invoke({\"a\":8,\"b\":9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5df3d387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiply'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c59ab020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiply two number'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply_tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "93b80948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': {'description': 'This is first number',\n",
       "  'required': True,\n",
       "  'title': 'A',\n",
       "  'type': 'integer'},\n",
       " 'b': {'description': 'This is second number',\n",
       "  'required': True,\n",
       "  'title': 'B',\n",
       "  'type': 'integer'}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply_tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "66af7ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import BaseTool\n",
    "from typing import Type\n",
    "\n",
    "class MutiplyTool(BaseTool):\n",
    "    name: str = \"mutiply_tool\"\n",
    "    description: str = \"This tool is used to multiply two numbers together\"\n",
    "    args_schema: Type[BaseModel] =  MultiplyInput\n",
    "    \n",
    "    def _run(self,a:int,b:int) -> int:\n",
    "        return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "748ff283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply_tool = MutiplyTool()\n",
    "multiply_tool.invoke({'a':8,'b':9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2367c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
